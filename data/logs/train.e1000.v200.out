[2024-03-24 12:30:48,460 INFO] Missing transforms field for corpus_1 data, set to default: [].
[2024-03-24 12:30:48,460 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.
[2024-03-24 12:30:48,460 INFO] Missing transforms field for valid data, set to default: [].
[2024-03-24 12:30:48,460 INFO] Parsed 2 corpora from -data.
[2024-03-24 12:30:48,460 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.
[2024-03-24 12:30:48,475 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's13\t3964\r', 's23\t1422\r', 's4\t791\r', 's98\t724\r', 's91\t646\r', 's57\t589\r']
[2024-03-24 12:30:48,491 INFO] The decoder start token is: <s>
[2024-03-24 12:30:48,491 INFO] Building model...
[2024-03-24 12:30:49,154 INFO] Switching model to float32 for amp/apex_amp
[2024-03-24 12:30:49,154 INFO] Non quantized layer compute is fp32
[2024-03-24 12:30:52,344 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(15816, 50, padding_idx=1)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (rnn): LSTM(50, 512, num_layers=2, batch_first=True, dropout=0.1)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(15816, 50, padding_idx=1)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.1, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(562, 512)
        (1): LSTMCell(512, 512)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=512, out_features=512, bias=False)
      (linear_out): Linear(in_features=1024, out_features=512, bias=False)
    )
  )
  (generator): Linear(in_features=512, out_features=15816, bias=True)
)
[2024-03-24 12:30:52,344 INFO] encoder: 4047120
[2024-03-24 12:30:52,344 INFO] decoder: 13995736
[2024-03-24 12:30:52,344 INFO] * number of parameters: 18042856
[2024-03-24 12:30:52,344 INFO] Trainable parameters = {'torch.float32': 18042856, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-24 12:30:52,344 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-24 12:30:52,344 INFO]  * src vocab size = 15816
[2024-03-24 12:30:52,344 INFO]  * tgt vocab size = 15816
[2024-03-24 12:30:52,819 INFO] Starting training on GPU: [0]
[2024-03-24 12:30:52,819 INFO] Start training loop and validate every 200 steps...
[2024-03-24 12:30:52,819 INFO] Scoring with: TransformPipe()
[2024-03-24 12:30:56,397 INFO] Weighted corpora loaded so far:
			* corpus_1: 1
[2024-03-24 12:30:59,755 INFO] Weighted corpora loaded so far:
			* corpus_1: 1
[2024-03-24 12:31:00,485 INFO] Weighted corpora loaded so far:
			* corpus_1: 2
[2024-03-24 12:31:00,501 INFO] Weighted corpora loaded so far:
			* corpus_1: 2
[2024-03-24 12:31:01,306 INFO] Weighted corpora loaded so far:
			* corpus_1: 3
[2024-03-24 12:31:01,415 INFO] Weighted corpora loaded so far:
			* corpus_1: 3
[2024-03-24 12:31:02,197 INFO] Weighted corpora loaded so far:
			* corpus_1: 4
[2024-03-24 12:31:02,349 INFO] Weighted corpora loaded so far:
			* corpus_1: 4
[2024-03-24 12:31:03,017 INFO] Weighted corpora loaded so far:
			* corpus_1: 5
[2024-03-24 12:31:03,151 INFO] Weighted corpora loaded so far:
			* corpus_1: 5
[2024-03-24 12:31:03,953 INFO] Weighted corpora loaded so far:
			* corpus_1: 6
[2024-03-24 12:31:04,094 INFO] Weighted corpora loaded so far:
			* corpus_1: 6
[2024-03-24 12:31:05,019 INFO] Weighted corpora loaded so far:
			* corpus_1: 7
[2024-03-24 12:31:05,150 INFO] Weighted corpora loaded so far:
			* corpus_1: 7
[2024-03-24 12:31:05,505 INFO] Weighted corpora loaded so far:
			* corpus_1: 8
[2024-03-24 12:31:05,697 INFO] Weighted corpora loaded so far:
			* corpus_1: 8
[2024-03-24 12:31:06,718 INFO] Weighted corpora loaded so far:
			* corpus_1: 9
[2024-03-24 12:31:06,891 INFO] Weighted corpora loaded so far:
			* corpus_1: 9
[2024-03-24 12:31:15,878 INFO] Step 50/ 1000; acc: 75.8; ppl:   3.9; xent: 1.3; lr: 0.00100; sents:    3200; bsz:  605/ 281/64; 1313/609 tok/s;     23 sec;
[2024-03-24 12:31:17,019 INFO] Step 100/ 1000; acc: 78.6; ppl:   1.5; xent: 0.4; lr: 0.00100; sents:    3200; bsz:  637/ 265/64; 27954/11619 tok/s;     24 sec;
[2024-03-24 12:31:18,288 INFO] Step 150/ 1000; acc: 86.0; ppl:   1.4; xent: 0.3; lr: 0.00100; sents:    3200; bsz:  609/ 272/64; 24000/10711 tok/s;     25 sec;
[2024-03-24 12:31:19,599 INFO] Step 200/ 1000; acc: 79.8; ppl:   1.6; xent: 0.5; lr: 0.00100; sents:    3200; bsz:  616/ 270/64; 23515/10315 tok/s;     27 sec;
[2024-03-24 12:31:32,438 INFO] valid stats calculation
                           took: 12.838934659957886 s.
[2024-03-24 12:31:32,439 INFO] Train perplexity: 1.91743
[2024-03-24 12:31:32,439 INFO] Train accuracy: 80.0309
[2024-03-24 12:31:32,439 INFO] Sentences processed: 12800
[2024-03-24 12:31:32,439 INFO] Average bsz:  617/ 272/64
[2024-03-24 12:31:32,439 INFO] Validation perplexity: 1.63653
[2024-03-24 12:31:32,439 INFO] Validation accuracy: 76.7237
[2024-03-24 12:31:33,579 INFO] Step 250/ 1000; acc: 82.8; ppl:   1.6; xent: 0.4; lr: 0.00100; sents:    3200; bsz:  622/ 272/64; 2225/971 tok/s;     41 sec;
[2024-03-24 12:31:34,882 INFO] Step 300/ 1000; acc: 83.8; ppl:   1.7; xent: 0.5; lr: 0.00100; sents:    3200; bsz:  608/ 277/64; 23341/10618 tok/s;     42 sec;
[2024-03-24 12:31:36,069 INFO] Step 350/ 1000; acc: 85.6; ppl:   1.4; xent: 0.4; lr: 0.00100; sents:    3200; bsz:  673/ 283/64; 28348/11930 tok/s;     43 sec;
[2024-03-24 12:31:37,138 INFO] Step 400/ 1000; acc: 93.8; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  588/ 260/64; 27493/12159 tok/s;     44 sec;
[2024-03-24 12:31:50,060 INFO] valid stats calculation
                           took: 12.922813177108765 s.
[2024-03-24 12:31:50,060 INFO] Train perplexity: 1.67712
[2024-03-24 12:31:50,060 INFO] Train accuracy: 83.2091
[2024-03-24 12:31:50,060 INFO] Sentences processed: 25600
[2024-03-24 12:31:50,060 INFO] Average bsz:  620/ 272/64
[2024-03-24 12:31:50,060 INFO] Validation perplexity: 1.27162
[2024-03-24 12:31:50,060 INFO] Validation accuracy: 93.2447
[2024-03-24 12:31:51,374 INFO] Step 450/ 1000; acc: 92.4; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  645/ 275/64; 2266/967 tok/s;     59 sec;
[2024-03-24 12:31:52,596 INFO] Step 500/ 1000; acc: 95.0; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  640/ 270/64; 26188/11028 tok/s;     60 sec;
[2024-03-24 12:31:53,974 INFO] Step 550/ 1000; acc: 93.7; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  611/ 273/64; 22166/9915 tok/s;     61 sec;
[2024-03-24 12:31:55,228 INFO] Step 600/ 1000; acc: 92.4; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  649/ 275/64; 25889/10979 tok/s;     62 sec;
[2024-03-24 12:32:08,038 INFO] valid stats calculation
                           took: 12.810098648071289 s.
[2024-03-24 12:32:08,045 INFO] Train perplexity: 1.5058
[2024-03-24 12:32:08,046 INFO] Train accuracy: 86.6037
[2024-03-24 12:32:08,046 INFO] Sentences processed: 38400
[2024-03-24 12:32:08,046 INFO] Average bsz:  625/ 273/64
[2024-03-24 12:32:08,046 INFO] Validation perplexity: 1.17555
[2024-03-24 12:32:08,046 INFO] Validation accuracy: 93.2447
[2024-03-24 12:32:09,319 INFO] Step 650/ 1000; acc: 95.7; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  628/ 268/64; 2230/949 tok/s;     76 sec;
[2024-03-24 12:32:10,772 INFO] Step 700/ 1000; acc: 91.9; ppl:   1.3; xent: 0.3; lr: 0.00100; sents:    3200; bsz:  680/ 275/64; 23391/9480 tok/s;     78 sec;
[2024-03-24 12:32:12,068 INFO] Step 750/ 1000; acc: 92.8; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  646/ 271/64; 24935/10468 tok/s;     79 sec;
[2024-03-24 12:32:13,419 INFO] Step 800/ 1000; acc: 95.8; ppl:   1.1; xent: 0.1; lr: 0.00100; sents:    3200; bsz:  631/ 267/64; 23322/9881 tok/s;     81 sec;
[2024-03-24 12:32:26,247 INFO] valid stats calculation
                           took: 12.82705044746399 s.
[2024-03-24 12:32:26,247 INFO] Train perplexity: 1.42453
[2024-03-24 12:32:26,247 INFO] Train accuracy: 88.4509
[2024-03-24 12:32:26,247 INFO] Sentences processed: 51200
[2024-03-24 12:32:26,247 INFO] Average bsz:  631/ 272/64
[2024-03-24 12:32:26,247 INFO] Validation perplexity: 1.29619
[2024-03-24 12:32:26,247 INFO] Validation accuracy: 93.2447
[2024-03-24 12:32:27,623 INFO] Step 850/ 1000; acc: 94.3; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  648/ 271/64; 2280/955 tok/s;     95 sec;
[2024-03-24 12:32:28,913 INFO] Step 900/ 1000; acc: 96.2; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  630/ 266/64; 24413/10321 tok/s;     96 sec;
[2024-03-24 12:32:30,232 INFO] Step 950/ 1000; acc: 95.7; ppl:   1.1; xent: 0.1; lr: 0.00100; sents:    3200; bsz:  668/ 268/64; 25330/10142 tok/s;     97 sec;
[2024-03-24 12:32:31,485 INFO] Step 1000/ 1000; acc: 95.2; ppl:   1.2; xent: 0.2; lr: 0.00100; sents:    3200; bsz:  572/ 269/64; 22812/10725 tok/s;     99 sec;
[2024-03-24 12:32:44,363 INFO] valid stats calculation
                           took: 12.878075122833252 s.
[2024-03-24 12:32:44,363 INFO] Train perplexity: 1.37489
[2024-03-24 12:32:44,363 INFO] Train accuracy: 89.8127
[2024-03-24 12:32:44,363 INFO] Sentences processed: 64000
[2024-03-24 12:32:44,363 INFO] Average bsz:  630/ 271/64
[2024-03-24 12:32:44,363 INFO] Validation perplexity: 1.19492
[2024-03-24 12:32:44,363 INFO] Validation accuracy: 93.2447
[2024-03-24 12:32:45,781 INFO] Saving checkpoint data/output/models/dblp/dblp.v12.json.filtered.mt75.ts3/_step_1000.pt
